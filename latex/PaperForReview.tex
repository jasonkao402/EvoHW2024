% CVPR 2022 Paper Template
% !TEX root = PaperForReview.tex
\documentclass[12pt,letterpaper]{article}

\usepackage{cvpr}
\usepackage{titling}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{CJKutf8}
\usepackage{geometry}
\usepackage{float}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
%  \setlength{\headheight}{15.0pt}
 \addtolength{\topmargin}{-3.0pt}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
% \usepackage{fancyhdr}
% \fancypagestyle{plain}{%  the preset of fancyhdr 
%     \fancyhf{} % clear all header and footer fields
%     \fancyhead[L]{Computer Vision Homework 1 Report}
%     \fancyhead[R]{\today}
% }
\makeatletter
% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\input{macros.tex}

\begin{document}
\begin{CJK}{UTF8}{bkai}
    %%%%%%%%% TITLE
    \title{Computer Vision Homework 1 Report}

    \author{
        陳均哲 \\
        313553020\\
        \and
        謝振杰\\
        313551085\\
        \and
        高聖傑\\
        313552011\\
    }

    \maketitle
\end{CJK}

\section{Introduction}
\label{sec:intro}
Camera calibration is a fundamental process in computer vision used to interpret images captured by cameras accurately. In this assignment, we will utilize 2D chessboard images as our calibration targets to compute the homography matrices for each image, derive the intrinsic matrix through Cholesky factorization, and determine the extrinsic matrices. Using intrinsic and extrinsic matrices, we are able to convert 2D image coordinates to 3D world coordinates. We've also compared our method with OpenCV's implementation in this assignment to determine the accuracy of our method.

Camera calibration has a wide range of applications across various fields. In augmented reality (AR), calibration enables virtual objects to be placed accurately within a real world environment. In autonomous driving, camera calibration ensures precise interpretation of the vehicle's surroundings for tasks like object detection and lane keeping.

\section{Implementation Procedure}
Camera calibration is about determining the intrinsic and extrinsic parameters of a camera that enable the conversion between 3D world coordinates and 2D pixel coordinates. To achieve this, we leverage linear algebra to calculate the homography matrices, intrinsic matrix, and extrinsic matrices step by step. This section will outline the implementation procedure used in our method.
% solve for these matrices step by step. This section will outline the mathematical approach used in our implementation.
\begin{enumerate}
    \item Compute Homography Matrices: For the $i$-th image, compute the homography matrix $H_i$ using the point correspondences.
    \item Solve for Intrinsic Matrix $K$: Use the homographies from multiple images and derive the intrinsic parameters by solving the system of equations that constrain $K$.
    \item Solve for Extrinsic Matrix ($[R|t]$):
          For the $i$-th image, compute the extrinsic parameters by decomposing
          $[R|t] = K^{-1}H_i$.
\end{enumerate}

These steps allow us to properly calibrate the camera, obtaining both the intrinsic and extrinsic parameters required for accurate 3D-to-2D transformations.

\subsection{Compute Homography Matrices $H_i$}
The main goal of camera calibration is to establish a relationship between known 3D world coordinates $(X_w, Y_w, Z_w)$ and their corresponding 2D image coordinates $(u, v)$, with scaling factor $s$. In practice, we often simplify the problem by assuming that the world coordinates lie on a chessboard, which is a 2D plane, and that the z-coordinate is zero, meaning $Z_w = 0$. Given these assumptions, the projection from 3D to 2D of $i$-th taken image can be represented as a homography transformation mapping matrix $H_i$ between two 2D planes:
\begin{equation}
    s\begin{bmatrix}
        u \\
        v \\
        1
    \end{bmatrix}
    = H_i \begin{bmatrix}
        X_w \\
        Y_w \\
        1
    \end{bmatrix}
    = \begin{bmatrix}
        h_1 & h_2 & h_3 \\
        h_4 & h_5 & h_6 \\
        h_7 & h_8 & h_9
    \end{bmatrix}_i
    \begin{bmatrix}
        X_w \\
        Y_w \\
        1
    \end{bmatrix}
\end{equation}
The homography matrix $H_i$ is a 3 x 3 homogeneous matrix, and $h_1, h_2, ..., h_9$ are the elements of the homography matrix $H_i$.
Rearranging the equation, we can obtain the following equations for $u$ and $v$:
\begin{equation}
    \begin{aligned}
        u = \frac{h_1X_w + h_2Y_w + h_3}{h_7X_w + h_8Y_w + h_9} \\
        v = \frac{h_4X_w + h_5Y_w + h_6}{h_7X_w + h_8Y_w + h_9}
    \end{aligned}
\end{equation}
Using the $N$ point correspondences between the 2D world coordinates $(X_w, Y_w)$ and their corresponding 2D image coordinates $(u, v)$,
For each pair of points, we can derive two linear equations, stacking $N$ of them together to form the linear system $Ah = 0$ :
\begin{equation}
    0 = Ah = \begin{bmatrix}
        -X_w & -Y_w & -1 & 0    & 0    & 0  & uX_w & uY_w & u \\
        0    & 0    & 0  & -X_w & -Y_w & -1 & vX_w & vY_w & v \\
    \end{bmatrix}
    \begin{bmatrix}
        h_1 \\
        h_2 \\
        h_3 \\
        h_4 \\
        h_5 \\
        h_6 \\
        h_7 \\
        h_8 \\
        h_9
    \end{bmatrix}
\end{equation}
Where $h = [h_1, h_2, ..., h_9]^T$ is the vectorized form of the homography matrix $H_i$. To solve for $h$, we use singular value decomposition (SVD) on matrix $A$. The last column of the resulting $V$ matrix from the SVD gives us the solution for $h$, and thus the homography matrix $H_i$. Noted that its final element, $h_9$, is typically set to 1 for normalization.
% We can stack the equations for all $N$ point correspondences to form the matrix $A$ and solve for $h$ using SVD gives us the homography matrix $H_i$.

\subsection{Find intrinsic matrix $K$ from $B$ with Cholesky factorization}
The intrinsic matrix $K$ for a pinhole camera model is typically defined as:
\begin{equation}
    K = \begin{bmatrix}
        f_x & s   & c_x \\
        0   & f_y & c_y \\
        0   & 0   & 1
    \end{bmatrix}
\end{equation}
Where $f_x$ and $f_y$ are the focal lengths along the focal lengths $x$ and $y$ axes. $s$ is the skew factor, which means the non-perpendicularity between the image axes. $(c_x, c_y)$ is the principal point, usually the center of the image.

For all of the $H_i$ in $i$-th calibration image, written as:
\begin{equation}
    H_i = K[R_i|t_i]
\end{equation}
Where $K$ is the intrinsic matrix, $R_i$ is the rotation matrix, and $t_i$ is the translation vector. By decomposing $H_i$ into $H_i = (h_1, h_2, h_3) = K(r_1, r_2, t)$, we can derive the orthogonality constraints for the rotation matrix $R_i$:
\begin{equation}
    r_1^Tr_2 = 0, \quad r_1^Tr_1 = r_2^Tr_2
    \label{eq:orthogonalityandequalScale}
\end{equation}

where $r_1=K^{-1}h_1$ and $r_2=K^{-1}h_2$ are the normalized rotation vectors and have equal scale, then we can derive the two equations for the intrinsic matrix $K$:
\begin{equation}
    h_1^{T}K^{-T}K^{-1}h_2 = 0, \quad h_1^{T}K^{-T}K^{-1}h_1 = h_2^{T}K^{-T}K^{-1}h_2
\end{equation}
which allows us to solve for the intrinsic matrix $K$ using Cholesky factorization:
\begin{equation}
    B = K^{-T}K^{-1}
\end{equation}
Where matrix $B$ has the property that it is symmetric and positive definite, and can be viewed as:
\begin{equation}
    B = \begin{bmatrix}
        b_{1} & b_{2} & b_{3} \\
        b_{2} & b_{4} & b_{5} \\
        b_{3} & b_{5} & b_{6}
    \end{bmatrix}
\end{equation}
Where $B$ can be simplify as $b = [b_1, b_2, b_3, b_4, b_5, b_6]^T$.
Since each homography gives us two linear constraints \xeq{eq:orthogonalityandequalScale}, for $n$ images, $2n$ linear equations can be formed.
Stacking these equations together, we can form a system of equations:
\begin{equation}
    Vb = 0
\end{equation}
Where V is the matrix that contains the coefficients of the unknowns $b$, which could be calculated from the homography matrices $H_i$.
SVD is used to find vector $b$ from the system of equations that minimize the error.

Once we have reconstructed the matrix $B$ from the vector $b$, we can recover the intrinsic matrix $K$ through Cholesky factorization. It decomposes $B$ into a lower triangular matrix $L$ and its transpose $L^T$, written as:
\begin{equation}
    B = L L^T
\end{equation}
Since $K$ is upper triangular, we can relate $L$ to $K$. From the elements of $B$, we can then recover $f_x$, $f_y$, $s$, $c_x$, and $c_y$ of the intrinsic matrix $K$.
\subsection{Find extrinsic matrix $[R_i|t_i]$ for each image}
Once we have the intrinsic matrix $K$, we can derive the extrinsic matrix $[R_i|t_i]$ for the $i$-th image by decomposing the homography matrix $H_i$ :
\begin{equation}
    H_i = K[R_i|t_i] \rightarrow [R_i|t_i] = K^{-1}H_i
\end{equation}
by decomposing $H_i$ and $R$ into columns in the form of $H_i = (h_1, h_2, h_3) = K(r_1, r_2, r_3, t)$,
we can solve for the rotation matrix $R_i$ and the translation vector $t_i$ with:
\begin{equation}
    \begin{aligned}
        r_1 & = sK^{-1}h_1 \\ r_2 & = sK^{-1}h_2 \\ r_3 & = r_1 \times r_2 \\ t & = sK^{-1}h_3
    \end{aligned}
\end{equation}
Where $s$ is the scaling factor, with its purpose to ensure that the extracted rotation vectors $r_1$ and $r_2$ have unit length.
By deriving the inverse of the intrinsic matrix $K \rightarrow K^{-1}$, and calculate the dot product of $K^{-1}$ and $h_1, h_2$ to get the magnitude of the rotation vectors $r_1$ and $r_2$, respectively, its now possible to normalize $r_1$ and $r_2$.
\begin{equation}
    s = \frac{2}{||K^{-1}h_1|| + ||K^{-1}h_2||}
\end{equation}
This method of normalizing with the average of $r_1$ and $r_2$ also have the benefit of correcting potential skewing distortion.
With $R_i$ and $t_i$ calculated, we can now visualize the extrinsic parameters of the camera for each image.

\section{Experimental Result}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|l|c|c|}
            \hline
                                                             & OpenCV & Our implementation \\ \hline
            Extrinsic visualization                          &
            \begin{minipage}{0.3\textwidth}
                \centering
                \vspace{4pt}
                \includegraphics[width=\textwidth]{images/0.png}
                \vspace{4pt}
            \end{minipage} &
            \begin{minipage}{0.3\textwidth}
                \centering
                \vspace{4pt}
                \includegraphics[width=\textwidth]{images/1.png}
                \vspace{4pt}
            \end{minipage}                                \\ \hline
            Intrinsic matrix ($K$)                           &
            \small{$
                    \begin{bmatrix}
                        3.180232e+03 & 0.000000e+00 & 1.639780e+03 \\
                        0.000000e+00 & 3.200460e+03 & 1.428066e+03 \\
                        0.000000e+00 & 0.000000e+00 & 1.000000e+00 \\
                    \end{bmatrix}
                $}
                                                             &
            \small{$
                    \begin{bmatrix}
                        3.400337e+03 & -3.525436e+01 & 1.475684e+03 \\
                        0.000000e+00 & 3.349359e+03  & 1.408228e+03 \\
                        0.000000e+00 & 0.000000e+00  & 1.000000e+00 \\
                    \end{bmatrix}
            $}                                                                             \\ \hline
        \end{tabular}
    }
    \caption{Result of homework provided dataset}
    \label{table:result_homework_dataset}
\end{table}

\begin{table}[htbp]
    \centering
    \resizebox{\textwidth}{!}{  % Adjust \textwidth to the desired width or specify a size
        \begin{tabular}{|l|c|c|}
            \hline
                                                             & OpenCV & Our implementation \\ \hline
            Extrinsic visualization                          &
            \begin{minipage}{0.3\textwidth}
                \centering
                \vspace{4pt}
                \includegraphics[width=\textwidth]{images/2.png}
                \vspace{4pt}
            \end{minipage} &
            \begin{minipage}{0.3\textwidth}
                \centering
                \vspace{4pt}
                \includegraphics[width=\textwidth]{images/3.png}
                \vspace{4pt}
            \end{minipage}                                \\ \hline
            Intrinsic matrix ($K$)                           &
            \small{$
                    \begin{bmatrix}
                        3.316606e+03 & 0.000000e+00 & 2.313158e+03 \\
                        0.000000e+00 & 3.321683e+03 & 1.718445e+03 \\
                        0.000000e+00 & 0.000000e+00 & 1.000000e+00 \\
                    \end{bmatrix}
                $}
                                                             &
            \small{$\begin{bmatrix}
                                3.479637e+03 & 2.289204e+00 & 2.337741e+03 \\
                                0.000000e+00 & 3.483098e+03 & 1.720712e+03 \\
                                0.000000e+00 & 0.000000e+00 & 1.000000e+00 \\
                            \end{bmatrix}
            $}                                                                             \\ \hline
        \end{tabular}
    }
    \caption{Result of self-captured dataset}
    \label{table:result_self_captured_dataset}
\end{table}
The experimental results are shown in table \xtabs{table:result_homework_dataset}{table:result_self_captured_dataset}. For our self-captured dataset, we collected 10 photos of the provided 7x10 chessboard with Samsung Galaxy A71. The results show that our method performs well on both the provided dataset and the self-captured dataset as the results are consistent with OpenCV's result.

\section{Discussion}
\subsection{Skew factor in intrinsic matrix ($K$)}
The skew factor ($k_{1,2}$) represents the angle between the x-axis and y-axis in an image. For most cameras, the skew factor should be zero since pixels are typically arranged in a rectangular grid where the x-axis and y-axis are perpendicular. However, the result of our camera calibration method produces a non-zero skew factor, while the OpenCV calibration method returns the correct value of 0. After examining OpenCV's source code, we discovered that the calculated skew factor is initially a non-zero value due to errors from the camera or the calibration process. However, OpenCV forces the factor to be set to 0 in its output. Therefore, it is reasonable for our method to yield a non-zero skew factor, as we retain all elements in their originally calculated form.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/code.png}
    \caption{OpenCV's source code from GitHub}
    \label{fig:code}
\end{figure}

\subsection{Deviation in extrinsic matrix calculation using OpenCV of our self-captured dataset}
We initially used an iPhone 13 Pro to collect our self-captured dataset. However, the extrinsic visualization calculated using OpenCV's method consistently displayed significant deviation compared to our method (as shown in \xfig{fig:code}). We believe the extrinsic visualization generated by our method aligns more closely with the actual camera position than OpenCV's results. This deviation puzzled us, so we reviewed our photos and the OpenCV documentation. We discovered that the iOS camera app chose a wide-angle lens to capture the chessboard images. For photos taken with wide-angle cameras, cv2.calibrateCameraExtended() should have been used instead of the standard cv2.calibrateCamera(). The latter makes several assumptions to improve precision for standard cameras, such as setting the skew factor to 0 and assuming no tangential distortion. However, with wide-angle lenses, which often exhibit significant distortion, these assumptions can lead to inaccurate results.
\begin{table}[htbp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|c|c|}
            \hline
            Extrinsic visualization of cv2.calibrateCamera()       & Extrinsic visualization of our method                   \\ \hline
            \includegraphics[width=0.5\textwidth]{images/left.png} & \includegraphics[width=0.5\textwidth]{images/right.png} \\ \hline
        \end{tabular}
    }
    \caption{Extrinsic visualization differences between OpenCV and our method}
    \label{table:ExtDifferences}
\end{table}
\section{Conclusion}
In this assignment, we implemented a camera calibration procedure from scratch. From computing homography matrices for various images, deriving intrinsic matrices using Cholesky factorization, and visualizing the calculated extrinsic matrices, we learned the whole camera calibration process. During our experiments, we also found some differences between the results from our method and OpenCV. Then we dug into OpenCV's source code and found the differences between both implementations.
Overall, this assignment deepened our understanding of camera calibration and enabled us to make more advanced adjustments to OpenCV in the future.
\begin{CJK}{UTF8}{bkai}
    \section{Work Assignment Plan}
    \noindent
    陳均哲: Implement camera calibration code. Report writing.\\
    謝振杰: Collect self-captured dataset. Report writing. Trace implementation of OpenCV.\\
    高聖傑: Collect self-captured dataset. Report writing.
\end{CJK}

%%%%%%%%% REFERENCES
% {\small
% \bibliographystyle{ieee_fullname}
% \bibliography{egbib.bib}
% }


\end{document}
